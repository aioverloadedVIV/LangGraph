{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a507d7d",
   "metadata": {},
   "source": [
    "## Project: Tweet Generator - Reflection with LangChain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a06c9a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".env file is loaded\n"
     ]
    }
   ],
   "source": [
    "# Loading the .env file\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "env_file = load_dotenv(find_dotenv(), override=True)\n",
    "if env_file:\n",
    "    print(\".env file is loaded\")\n",
    "else:\n",
    "    print(\".env file not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b522b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication Successful with OpenAI.\n"
     ]
    }
   ],
   "source": [
    "# importing the necessary libraries\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "client = ChatOpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "if client:\n",
    "    print(\"Authentication Successful with OpenAI.\")\n",
    "else:\n",
    "    print(\"Authentication Failed with OpenAI\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f86c939",
   "metadata": {},
   "source": [
    "#### GENERATE - This generates the initial responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68c5136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a chat prompt template\n",
    "# MessagesPlaceholder - is a dynamic part of the prompt, that will be filled with all the revision from the reflector later on.\n",
    "generation_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            'system',\n",
    "            '''You are a Twitter expert assigned to craft outstanding tweets.\n",
    "            Generate the most engaging and impactful tweet possible based on the user's request.\n",
    "            If the user provides feedback, refine and enhance your previous attempts accordingly for maximum engagement.'''\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "# using LCEL (LangChain Expression Language) to create the generate_chain\n",
    "generate_chain = generation_prompt | llm  # feeding the generation prompt into the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aadf8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['messages'], input_types={'messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x12b79b100>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"You are a Twitter expert assigned to craft outstanding tweets.\\n            Generate the most engaging and impactful tweet possible based on the user's request.\\n            If the user provides feedback, refine and enhance your previous attempts accordingly for maximum engagement.\"), additional_kwargs={}), MessagesPlaceholder(variable_name='messages')])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x12ec7d640>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x12f8c6210>, root_client=<openai.OpenAI object at 0x139324080>, root_async_client=<openai.AsyncOpenAI object at 0x12f8c48c0>, model_name='gpt-4o-mini', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d0d4206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç‚öΩÔ∏è Excitement is building for the FIFA World Cup 2026! üèÜ‚ú® With matches spread across the USA, Canada, and Mexico, it's set to be the biggest celebration of football yet! Who are you rooting for? Let the countdown begin! ‚åõÔ∏èüá∫üá∏üá®üá¶üá≤üáΩ #WorldCup2026 #FootballFever #SoccerUnited"
     ]
    }
   ],
   "source": [
    "tweet = \"\" # to store the generated tweet\n",
    "\n",
    "request = HumanMessage(\n",
    "    content = \"FIFA World Cup 26\"\n",
    ")\n",
    "\n",
    "# Streaming the response from generate chain\n",
    "for chunk in generate_chain.stream(\n",
    "    {'messages': [request]}\n",
    "):\n",
    "    print(chunk.content, end='')\n",
    "    tweet += chunk.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f1c186",
   "metadata": {},
   "source": [
    "### Reflect and Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c544f933",
   "metadata": {},
   "outputs": [],
   "source": [
    "reflection_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a Twitter influencer known for your engaging content and sharp insights.\n",
    "            Review and critique the user's tweet. \n",
    "            Provide constructive Feedback, focusing on enhancing it's depth, style and overall impact.\n",
    "            Offer specific suggestions to make the tweet more compelling and engaging for their audience.\"\"\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"), # here it contains the history messages for Agents to critise and make recommendations for improving.\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "reflect_chain = reflection_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2435cce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['messages'], input_types={'messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x12b79b100>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"You are a Twitter influencer known for your engaging content and sharp insights.\\n            Review and critique the user's tweet. \\n            Provide constructive Feedback, focusing on enhancing it's depth, style and overall impact.\\n            Offer specific suggestions to make the tweet more compelling and engaging for their audience.\"), additional_kwargs={}), MessagesPlaceholder(variable_name='messages')])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x13a419c70>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1381e52b0>, root_client=<openai.OpenAI object at 0x13a5decc0>, root_async_client=<openai.AsyncOpenAI object at 0x1381e6000>, model_name='gpt-4o-mini', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reflect_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f679da36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your tweet does a great job of capturing the excitement surrounding the FIFA World Cup 2026! The emojis add a fun and engaging visual element, and you‚Äôve effectively highlighted the diversity of the event by mentioning the three host countries. Here‚Äôs some constructive feedback to enhance its depth, style, and overall impact:\n",
      "\n",
      "1. **Add a Personal Touch**: Share your personal connection to the World Cup or a memorable moment from past tournaments. This invites your followers to engage on a more personal level.\n",
      "   - **Suggestion**: \"As a lifelong fan, I can‚Äôt wait to see how the energy of the fans in the USA, Canada, and Mexico will shape this historic event!\"\n",
      "\n",
      "2. **Pose a Thought-Provoking Question**: Instead of just asking who people are rooting for, you could delve deeper. \n",
      "   - **Suggestion**: \"Which underdog team do you think will surprise us this year?\" This invites more discussion.\n",
      "\n",
      "3. **Incorporate a Fact or Statistic**: A compelling fact can pique interest and provide context.\n",
      "   - **Suggestion**: \"Did you know this will be the first World Cup to feature 48 teams? That‚Äôs more football and more excitement!\"\n",
      "\n",
      "4. **Call to Action**: Encourage your followers to share their own thoughts or experiences.\n",
      "   - **Suggestion**: \"Share your favorite World Cup memory or prediction in the comments! Let‚Äôs see what the community thinks!\"\n",
      "\n",
      "5. **Use Hashtags Strategically**: While your hashtags are relevant, consider adding a few more that could broaden your reach or focus on specific aspects.\n",
      "   - **Suggestion**: Added hashtags like #FIFA2026 #SoccerCulture or #WorldCupMemories can attract more engagement.\n",
      "\n",
      "Here‚Äôs a revised version incorporating these suggestions:\n",
      "\n",
      "üåç‚öΩÔ∏è Excitement is building for the FIFA World Cup 2026! üèÜ‚ú® As a lifelong fan, I can‚Äôt wait to see how the energy of the fans in the USA, Canada, and Mexico will shape this historic event! Did you know this will be the first World Cup featuring 48 teams? That‚Äôs more football excitement! ü•≥ Who‚Äôs your underdog pick to surprise us? Share your favorite World Cup memory or prediction! Let the countdown begin! ‚åõÔ∏èüá∫üá∏üá®üá¶üá≤üáΩ #WorldCup2026 #FootballFever #SoccerUnited #FIFA2026 #SoccerCulture\n",
      "\n",
      "This version adds depth and invites more interaction, making it more compelling for your audience!"
     ]
    }
   ],
   "source": [
    "reflection = \"\" # to store the generated tweet\n",
    "\n",
    "# Streaming the response from reflect chain using generate_chain initial tweet\n",
    "for chunk in reflect_chain.stream(\n",
    "    {\"messages\": [request, HumanMessage(content = tweet)]}\n",
    "):\n",
    "    print(chunk.content, end=\"\")\n",
    "    reflection += chunk.content \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c26435",
   "metadata": {},
   "outputs": [],
   "source": [
    "## with Generator : Response is -\n",
    "üåç‚öΩÔ∏è Excitement is building for the FIFA World Cup 2026! üèÜ‚ú® With matches spread across the USA, Canada, and Mexico, it's set to be the biggest celebration of football yet! Who are you rooting for? Let the countdown begin! ‚åõÔ∏èüá∫üá∏üá®üá¶üá≤üáΩ #WorldCup2026 #FootballFever #SoccerUnited\n",
    "\n",
    "## With Reflector : Response is - \n",
    "\n",
    "üåç‚öΩÔ∏è Excitement is building for the FIFA World Cup 2026! üèÜ‚ú® As a lifelong fan, I can‚Äôt wait to see how the energy of the fans in the USA, Canada, and Mexico will shape this historic event! Did you know this will be the first World Cup featuring 48 teams? That‚Äôs more football excitement! ü•≥ Who‚Äôs your underdog pick to surprise us? Share your favorite World Cup memory or prediction! Let the countdown begin! ‚åõÔ∏èüá∫üá∏üá®üá¶üá≤üáΩ #WorldCup2026 #FootballFever #SoccerUnited #FIFA2026 #SoccerCulture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42712ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç‚öΩÔ∏è The excitement for the FIFA World Cup 2026 is off the charts! üèÜ‚ú® As a lifelong fan, I can't wait to see how the energy of the fans in the USA, Canada, and Mexico shapes this historic event! Did you know it‚Äôs the first World Cup featuring 48 teams? More football, more thrills! ü•≥ \n",
      "\n",
      "Which underdog team do you think will surprise us this year? Share your favorite World Cup memory or prediction in the comments! Let‚Äôs kick off this countdown together! ‚åõÔ∏èüá∫üá∏üá®üá¶üá≤üáΩ #WorldCup2026 #FootballFever #SoccerUnited #FIFA2026 #SoccerCulture"
     ]
    }
   ],
   "source": [
    "## Call Generator_chain with initial tweet and reflections as input \n",
    "\n",
    "for chunk in generate_chain.stream(\n",
    "    {\"messages\": [request, AIMessage(content=tweet), HumanMessage(content=reflection)]}\n",
    "):\n",
    "    print(chunk.content, end = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd964dcc",
   "metadata": {},
   "source": [
    "### Define the Graph - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489c6fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# First, define a TypedDict to structure your state, with the \"messages\" key to accumulate messages via a reducer like add_messages.\n",
    "# This ensures that each node‚Äôs messages get appended, not overwritten. \n",
    "\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "988b4286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define your state schema\n",
    "## Graph - State Schema\n",
    "class State(TypedDict):\n",
    "    # Accumulate messages across nodes\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "# 2. Define your nodes as State ‚Üí State transitions\n",
    "## Nodes\n",
    "# define a function for the generation node\n",
    "def generation_node(state: State) -> dict:\n",
    "    \"\"\"Call the generator with the running message history and append its reply.\"\"\"\n",
    "    ai_msg: BaseMessage = generate_chain.invoke({\"messages\": state[\"messages\"]})\n",
    "    return {\"messages\": [ai_msg]}\n",
    "\n",
    "def reflection_node(state: State) -> dict:\n",
    "    \"\"\"\n",
    "    Reflect on the conversation so far and append feedback as a HumanMessage\n",
    "    (so the generator treats it like human guidance).\n",
    "    \"\"\"\n",
    "    cls_map = {\"ai\": HumanMessage, \"human\": AIMessage}\n",
    "    msgs = state[\"messages\"]\n",
    "    translated = [msgs[0]] + [cls_map[m.type](content=m.content) for m in msgs[1:]]\n",
    "    res: BaseMessage = reflect_chain.invoke({\"messages\": translated})\n",
    "    return {\"messages\": [HumanMessage(content=res.content)]}\n",
    "\n",
    "# ---- Control flow ----\n",
    "MAX_ITERATIONS = 3\n",
    "\n",
    "def should_continue(state: State):\n",
    "    \"\"\"Stop after MAX_ITERATIONS generated messages, otherwise go to 'reflect'.\"\"\"\n",
    "    if len(state[\"messages\"]) > MAX_ITERATIONS:\n",
    "        return END\n",
    "    return \"reflect\"\n",
    "\n",
    "builder = StateGraph(state_schema=State)\n",
    "builder.add_node(\"generate\", generation_node)\n",
    "builder.add_node(\"reflect\", reflection_node)\n",
    "\n",
    "# setting the generate node as the starting point\n",
    "builder.set_entry_point(\"generate\")\n",
    "\n",
    "# adding a conditional edge to the graph\n",
    "builder.add_conditional_edges(\"generate\", should_continue)\n",
    "builder.add_edge(\"reflect\", \"generate\")\n",
    "\n",
    "# compiling the graph\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "041282d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the graph\n",
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46726828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate a tweet about FIFA World Cup 26\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "üåç‚öΩÔ∏è Get ready for the ultimate showdown! The FIFA World Cup 2026 is coming to North America, where passion meets the pitch! üá∫üá∏üá®üá¶üá≤üáΩ Who's your pick to lift the trophy? üèÜ Let the countdown begin! #WorldCup2026 #FIFA #SoccerLove\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "This tweet has a lot of great elements! It‚Äôs enthusiastic, visually engaging with emojis, and invites interaction by asking a question. However, to enhance its depth, style, and overall impact, consider the following suggestions:\n",
      "\n",
      "1. **Add a Unique Angle**: Instead of a general statement about the World Cup, incorporate a specific aspect that makes this event unique. You could mention the diversity of the host countries or the historical significance of the tournament being held across three nations.\n",
      "\n",
      "2. **Incorporate a Personal Touch**: Share your own thoughts or feelings about the event. This would make it more relatable and engaging. For example, you could talk about a memorable moment from past World Cups that gets you excited for 2026.\n",
      "\n",
      "3. **Use a Stronger Call to Action**: Instead of just asking who people think will win, invite them to share their favorite memories or predictions in a more engaging way, like ‚ÄúShare your favorite World Cup moment or prediction below! üëá‚Äù\n",
      "\n",
      "Here‚Äôs a revised version of your tweet:\n",
      "\n",
      "üåç‚öΩÔ∏è The countdown to the FIFA World Cup 2026 has begun! With the tournament spanning üá∫üá∏üá®üá¶üá≤üáΩ, we‚Äôre in for a celebration of culture and soccer like never before. What‚Äôs your favorite World Cup memory? üèÜ Let‚Äôs relive the magic! #WorldCup2026 #FIFA #SoccerLove\n",
      "\n",
      "This version retains your excitement but adds depth and personal connection, enhancing overall engagement!\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "üåç‚öΩÔ∏è The countdown to the FIFA World Cup 2026 has begun! With this historic tournament uniting üá∫üá∏üá®üá¶üá≤üáΩ, we‚Äôre set for a vibrant celebration of culture and soccer! What‚Äôs your favorite World Cup memory that gets you hyped? üèÜ Let‚Äôs relive the magic together! üëá #WorldCup2026 #FIFA #SoccerLove\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# NEW: pass a state dict with a \"messages\" list\n",
    "inputs = {\"messages\": [HumanMessage(content=\"Generate a tweet about FIFA World Cup 26\")]}\n",
    "\n",
    "# Invoke the graph and get the final state back\n",
    "final_state = graph.invoke(inputs)\n",
    "\n",
    "# Print all messages in the final state\n",
    "for msg in final_state[\"messages\"]:\n",
    "    print(msg.content)\n",
    "    print(\"\\n\" + \"-\" * 100 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9d0be0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5db262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7688239b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63be6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf0e9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
